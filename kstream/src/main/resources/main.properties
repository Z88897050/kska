####################################################
#### encoding----UTF-8
#### 数据格式解析错误会产生一条WARN日志,不会关闭server
#### 配置文件格式错误以及不支持的操作会退出server
####################################################
#### 多值使用半角逗号分隔
#### 多条件使用半角分号分隔
#### 键值之间使用半角冒号
####################################################
#### topic,operation等配置文件需和启动的server文件同一目录
#### key.serde,value.serde只可为String
####################################################
#####################################################
############### kafka stream config #################
#### kafka stream config
# An identifier for the stream processing application.
# Must be unique within the Kafka cluster. It is used as:
# 1) the default client-id prefix,
# 2) the group-id for membership management,
# 3) the changelog topic prefix.
application.id=
application.name=
# kafka address,need configure
bootstrap.servers=
# Maximum number of memory bytes to be used for buffering across all threads
cache.max.bytes.buffering=10485760
# The number of threads to execute stream processing.
num.stream.threads=1
# The processing guarantee that should be used. Possible values are at_least_once (default) and exactly_once.
processing.guarantee=at_least_once
# The maximum number of records to buffer per partition.
buffered.records.per.partition=1000
# The frequency with which to save the position of the processor.
# Note, if 'processing.guarantee' is set to 'exactly_once', the default value is 100,otherwise the default value is 30000.
commit.interval.ms=30000
# earliest: automatically reset the offset to the earliest offset;
# latest: automatically reset the offset to the latest offset(default);
# none: throw exception to the consumer if no previous offset is found for the consumer's group;
# anything else: throw exception to the consumer.
auto.offset.reset=latest
####################################################
################### kSource ########################
# 输入源的文件名
ks.source=
##################### kOperation ####################
# operation的文件名,同一kSource顺序按照所列先后.文件名之间半角逗号分隔.
ks.operation=
################### kOutput ########################
# 输出操作的文件名
ks.output=
################### zookeeper connect ###############
# kafka集群的zookeeper地址,如果是test,停止ks后会自动删除中间结果topic.
ks.zookeeper.url=
####################################################
##################### dicSet #######################
# filter,mapper等操作使用的字典
# kafka,array.注意区分大小写
dic.type=
# dic映射的字段名.
dic.fields=
# 存储对应kafka中的topic,与fields对应.如:t1,t2...
dic.kafka.topics=
# 存储对应kafka的地址.未配置则使用bootstrap.servers地址.如:127.0.0.1:9092
dic.kafka.address=
# 存储type是array的多组值,如：f11,f12,f13...;f21,f22,f23...
dic.array.values=